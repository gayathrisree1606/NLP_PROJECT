{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/draft_50000 (1).csv')\n",
        "\n",
        "\n",
        "\n",
        "# Text preprocessing\n",
        "df['text'] = df['text'].str.lower().str.replace('[^\\w\\s]', '', regex=True)\n",
        "df.dropna(subset=['text', 'class'], inplace=True)\n",
        "\n",
        "# Naive Bayes with TF-IDF\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "X_tfidf = tfidf.fit_transform(df['text'])\n",
        "y = df['class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_tfidf = MultinomialNB()\n",
        "model_tfidf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_tfidf = model_tfidf.predict(X_test)\n",
        "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
        "print('\\n')\n",
        "print(f'Accuracy (TF-IDF): {accuracy_tfidf:.2f}')\n",
        "conf_matrix_tfidf = confusion_matrix(y_test, y_pred_tfidf)\n",
        "print('Confusion Matrix (TF-IDF):')\n",
        "print(conf_matrix_tfidf)\n",
        "class_report_tfidf = classification_report(y_test, y_pred_tfidf)\n",
        "print('Classification Report (TF-IDF):')\n",
        "print(class_report_tfidf)\n",
        "\n",
        "\n",
        "\n",
        "# Naive Bayes with Word2Vec\n",
        "\n",
        "sentences = [text.split() for text in df['text']]\n",
        "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "\n",
        "X_w2v = []\n",
        "for sentence in sentences:\n",
        "    sentence_vectors = [word2vec_model.wv[word] for word in sentence if word in word2vec_model.wv]\n",
        "    if sentence_vectors:\n",
        "        X_w2v.append(np.mean(sentence_vectors, axis=0))\n",
        "    else:\n",
        "        X_w2v.append(np.zeros(word2vec_model.vector_size))\n",
        "X_w2v = np.array(X_w2v)\n",
        "\n",
        "\n",
        "X_w2v -= X_w2v.min()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_w2v, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_w2v = MultinomialNB()\n",
        "model_w2v.fit(X_train, y_train)\n",
        "\n",
        "y_pred_w2v = model_w2v.predict(X_test)\n",
        "accuracy_w2v = accuracy_score(y_test, y_pred_w2v)\n",
        "print('\\n')\n",
        "print(f'Accuracy (Word2Vec): {accuracy_w2v:.2f}')\n",
        "conf_matrix_w2v = confusion_matrix(y_test, y_pred_w2v)\n",
        "print('Confusion Matrix (Word2Vec):')\n",
        "print(conf_matrix_w2v)\n",
        "class_report_w2v = classification_report(y_test, y_pred_w2v)\n",
        "print('Classification Report (Word2Vec):')\n",
        "print(class_report_w2v)\n",
        "\n",
        "\n",
        "# Naive Bayes with CountVectorizer\n",
        "\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "X_count = count_vectorizer.fit_transform(df['text'])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_count, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model_count = MultinomialNB()\n",
        "model_count.fit(X_train, y_train)\n",
        "\n",
        "y_pred_count = model_count.predict(X_test)\n",
        "accuracy_count = accuracy_score(y_test, y_pred_count)\n",
        "print('\\n')\n",
        "print(f'Accuracy (CountVectorizer): {accuracy_count:.2f}')\n",
        "conf_matrix_count = confusion_matrix(y_test, y_pred_count)\n",
        "print('Confusion Matrix (CountVectorizer):')\n",
        "print(conf_matrix_count)\n",
        "class_report_count = classification_report(y_test, y_pred_count)\n",
        "print('Classification Report (CountVectorizer):')\n",
        "print(class_report_count)\n",
        "\n",
        "\n",
        "\n",
        "# Naive Bayes with GloVE\n",
        "\n",
        "glove_file = '/content/glove.6B.100d.txt'\n",
        "glove_embeddings = {}\n",
        "with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_embeddings[word] = vector\n",
        "\n",
        "max_length = 100\n",
        "\n",
        "X_glove = []\n",
        "for sentence in sentences:\n",
        "    sentence_vectors = [glove_embeddings[word] for word in sentence if word in glove_embeddings]\n",
        "    if sentence_vectors:\n",
        "        sentence_vector = np.mean(sentence_vectors, axis=0)\n",
        "    else:\n",
        "        sentence_vector = np.zeros(max_length)\n",
        "\n",
        "\n",
        "    sentence_vector = list(sentence_vector)\n",
        "    sentence_vector += [0.0] * (max_length - len(sentence_vector))\n",
        "    sentence_vector = sentence_vector[:max_length]\n",
        "\n",
        "    X_glove.append(sentence_vector)\n",
        "\n",
        "X_glove = np.array(X_glove)\n",
        "\n",
        "X_glove -= X_glove.min()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_glove, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train -= X_train.min()\n",
        "X_test -= X_test.min()\n",
        "\n",
        "\n",
        "model_glove = MultinomialNB()\n",
        "model_glove.fit(X_train, y_train)\n",
        "print('\\n')\n",
        "\n",
        "y_pred_glove = model_glove.predict(X_test)\n",
        "accuracy_glove = accuracy_score(y_test, y_pred_glove)\n",
        "print(f'Accuracy (GloVE): {accuracy_glove:.2f}')\n",
        "conf_matrix_glove = confusion_matrix(y_test, y_pred_glove)\n",
        "print('Confusion Matrix (GloVE):')\n",
        "print(conf_matrix_glove)\n",
        "class_report_glove = classification_report(y_test, y_pred_glove)\n",
        "print('Classification Report (GloVE):')\n",
        "print(class_report_glove)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFSts2eS28Me",
        "outputId": "7b049394-3fcf-401a-9c65-4e813bff01ba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Accuracy (TF-IDF): 0.88\n",
            "Confusion Matrix (TF-IDF):\n",
            "[[3925 1010]\n",
            " [ 182 4881]]\n",
            "Classification Report (TF-IDF):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.80      0.87      4935\n",
            "           1       0.83      0.96      0.89      5063\n",
            "\n",
            "    accuracy                           0.88      9998\n",
            "   macro avg       0.89      0.88      0.88      9998\n",
            "weighted avg       0.89      0.88      0.88      9998\n",
            "\n",
            "\n",
            "\n",
            "Accuracy (Word2Vec): 0.85\n",
            "Confusion Matrix (Word2Vec):\n",
            "[[3958  977]\n",
            " [ 508 4555]]\n",
            "Classification Report (Word2Vec):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.80      0.84      4935\n",
            "           1       0.82      0.90      0.86      5063\n",
            "\n",
            "    accuracy                           0.85      9998\n",
            "   macro avg       0.85      0.85      0.85      9998\n",
            "weighted avg       0.85      0.85      0.85      9998\n",
            "\n",
            "\n",
            "\n",
            "Accuracy (CountVectorizer): 0.89\n",
            "Confusion Matrix (CountVectorizer):\n",
            "[[3981  954]\n",
            " [ 193 4870]]\n",
            "Classification Report (CountVectorizer):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.81      0.87      4935\n",
            "           1       0.84      0.96      0.89      5063\n",
            "\n",
            "    accuracy                           0.89      9998\n",
            "   macro avg       0.89      0.88      0.88      9998\n",
            "weighted avg       0.89      0.89      0.88      9998\n",
            "\n",
            "\n",
            "\n",
            "Accuracy (GloVE): 0.74\n",
            "Confusion Matrix (GloVE):\n",
            "[[2675 2260]\n",
            " [ 313 4750]]\n",
            "Classification Report (GloVE):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.54      0.68      4935\n",
            "           1       0.68      0.94      0.79      5063\n",
            "\n",
            "    accuracy                           0.74      9998\n",
            "   macro avg       0.79      0.74      0.73      9998\n",
            "weighted avg       0.79      0.74      0.73      9998\n",
            "\n"
          ]
        }
      ]
    }
  ]
}