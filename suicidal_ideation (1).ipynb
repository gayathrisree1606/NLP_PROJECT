{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs6fANMjW896",
        "outputId": "9c297f72-a161-40a5-a633-83775898ab86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                               text  class\n",
            "0       51297  get crush guy definitely way old laugh literal...      0\n",
            "1       24705   go to july 2018i hope 8 month enough change mind      1\n",
            "2      185969  want live anymore 23 right thinking end life p...      1\n",
            "3      201675  every time get period want kill already depres...      1\n",
            "4       52701  story incomplete similar story op case dad spe...      1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  50000 non-null  int64 \n",
            " 1   text        49989 non-null  object\n",
            " 2   class       50000 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "file_path = '/content/draft_50000 (1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "\n",
        "data.dropna(inplace=True)\n",
        "data['text'] = data['text'].str.lower()\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "data['class'] = label_encoder.fit_transform(data['class'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['class'], test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction using Count Vectorizer and Model Training using Logistic Regression"
      ],
      "metadata": {
        "id": "H11G2KQ_ZMiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_cv = count_vectorizer.fit_transform(X_train)\n",
        "X_test_cv = count_vectorizer.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "\n",
        "lr_model.fit(X_train_cv, y_train)\n",
        "\n",
        "y_pred = lr_model.predict(X_test_cv)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkEGpWLPYyJW",
        "outputId": "d167def8-51d8-4d0f-86d0-a0132ed4d89f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.92      4935\n",
            "           1       0.94      0.90      0.92      5063\n",
            "\n",
            "    accuracy                           0.92      9998\n",
            "   macro avg       0.92      0.92      0.92      9998\n",
            "weighted avg       0.92      0.92      0.92      9998\n",
            "\n",
            "Accuracy: 0.9212842568513703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Feature Extraction using Tfidf and Model Training using Logistic Regression"
      ],
      "metadata": {
        "id": "MFEK2tF9aCPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred = lr_model.predict(X_test_tfidf)\n",
        "\n",
        "print('Logistic Regression with TF-IDF')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL7CXtm7ZY-y",
        "outputId": "97f56547-7b7f-4ca9-e0bc-0493c9a7de85"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression with TF-IDF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93      4935\n",
            "           1       0.94      0.92      0.93      5063\n",
            "\n",
            "    accuracy                           0.93      9998\n",
            "   macro avg       0.93      0.93      0.93      9998\n",
            "weighted avg       0.93      0.93      0.93      9998\n",
            "\n",
            "Accuracy: 0.9319863972794559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction using word2vec and Model Training using Logistic Regression"
      ],
      "metadata": {
        "id": "ehRrtj6QpMAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "import numpy as np\n",
        "\n",
        "X_train_tokens = X_train.apply(gensim.utils.simple_preprocess)\n",
        "X_test_tokens = X_test.apply(gensim.utils.simple_preprocess)\n",
        "\n",
        "w2v_model = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "\n",
        "def document_vector(tokens, model):\n",
        "\n",
        "    tokens = [token for token in tokens if token in model.wv.key_to_index]\n",
        "    if len(tokens) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(model.wv[tokens], axis=0)\n",
        "\n",
        "X_train_w2v = np.array([document_vector(tokens, w2v_model) for tokens in X_train_tokens])\n",
        "X_test_w2v = np.array([document_vector(tokens, w2v_model) for tokens in X_test_tokens])\n"
      ],
      "metadata": {
        "id": "hykLQjc4aJX3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "lr_model.fit(X_train_w2v, y_train)\n",
        "\n",
        "y_pred = lr_model.predict(X_test_w2v)\n",
        "\n",
        "print('Logistic Regression with Word2Vec')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvuD4qLCawkm",
        "outputId": "6abbaa99-42d0-493e-cdee-d47e137f7b63"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression with Word2Vec\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      4935\n",
            "           1       0.89      0.91      0.90      5063\n",
            "\n",
            "    accuracy                           0.90      9998\n",
            "   macro avg       0.90      0.90      0.90      9998\n",
            "weighted avg       0.90      0.90      0.90      9998\n",
            "\n",
            "Accuracy: 0.9002800560112022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction using Glove and Model Training using Logistic Regression"
      ],
      "metadata": {
        "id": "ynRqJq6FgtXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Load data\n",
        "file_path = '/content/draft_50000 (1).csv'  # Update this path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Basic preprocessing\n",
        "data.dropna(inplace=True)\n",
        "data['text'] = data['text'].str.lower()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "data['class'] = label_encoder.fit_transform(data['class'])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['class'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Unzip GloVe file\n",
        "glove_zip_path = '/content/glove.6B.zip'  # Update this path to the GloVe zip file\n",
        "glove_txt_path = '/content/glove.6B.100d.txt'  # Change this if you're using a different dimension\n",
        "\n",
        "if not os.path.exists(glove_txt_path):\n",
        "    with zipfile.ZipFile(glove_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extract(glove_txt_path)\n",
        "\n",
        "# Load GloVe vectors\n",
        "def load_glove_embeddings(glove_file_path):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_txt_path)\n",
        "\n",
        "# Tokenize the text data\n",
        "X_train_tokens = X_train.apply(simple_preprocess)\n",
        "X_test_tokens = X_test.apply(simple_preprocess)\n",
        "\n",
        "# Function to compute the average GloVe vector for a document\n",
        "def document_vector(tokens, embeddings_index, vector_size):\n",
        "    # Remove out-of-vocabulary words\n",
        "    tokens = [token for token in tokens if token in embeddings_index]\n",
        "    if len(tokens) == 0:\n",
        "        return np.zeros(vector_size)\n",
        "    return np.mean([embeddings_index[token] for token in tokens], axis=0)\n",
        "\n",
        "# Compute document vectors for the training and testing sets\n",
        "vector_size = 100  # GloVe vector size\n",
        "X_train_glove = np.array([document_vector(tokens, glove_embeddings, vector_size) for tokens in X_train_tokens])\n",
        "X_test_glove = np.array([document_vector(tokens, glove_embeddings, vector_size) for tokens in X_test_tokens])\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "lr_model.fit(X_train_glove, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lr_model.predict(X_test_glove)\n",
        "\n",
        "# Evaluate the model\n",
        "print('Logistic Regression with GloVe')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGvxgOnoa94S",
        "outputId": "66d288b1-60cc-4d4f-8efa-3d982d054547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression with GloVe\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.82      0.85      4935\n",
            "           1       0.84      0.89      0.86      5063\n",
            "\n",
            "    accuracy                           0.86      9998\n",
            "   macro avg       0.86      0.86      0.86      9998\n",
            "weighted avg       0.86      0.86      0.86      9998\n",
            "\n",
            "Accuracy: 0.8554710942188438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction using Glove and Model Training using Decision Tree"
      ],
      "metadata": {
        "id": "TxYdWlbYhg4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "glove_zip_path = '/content/glove.6B.zip'\n",
        "glove_txt_path = '/content/glove.6B.100d.txt'\n",
        "\n",
        "if not os.path.exists(glove_txt_path):\n",
        "    with zipfile.ZipFile(glove_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extract(glove_txt_path)\n",
        "\n",
        "# Load GloVe vectors\n",
        "def load_glove_embeddings(glove_file_path):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_txt_path)\n",
        "\n",
        "# Tokenize the text data\n",
        "X_train_tokens = X_train.apply(simple_preprocess)\n",
        "X_test_tokens = X_test.apply(simple_preprocess)\n",
        "\n",
        "# Function to compute the average GloVe vector for a document\n",
        "def document_vector(tokens, embeddings_index, vector_size):\n",
        "    # Remove out-of-vocabulary words\n",
        "    tokens = [token for token in tokens if token in embeddings_index]\n",
        "    if len(tokens) == 0:\n",
        "        return np.zeros(vector_size)\n",
        "    return np.mean([embeddings_index[token] for token in tokens], axis=0)\n",
        "\n",
        "# Compute document vectors for the training and testing sets\n",
        "vector_size = 100  # GloVe vector size\n",
        "X_train_glove = np.array([document_vector(tokens, glove_embeddings, vector_size) for tokens in X_train_tokens])\n",
        "X_test_glove = np.array([document_vector(tokens, glove_embeddings, vector_size) for tokens in X_test_tokens])\n",
        "\n",
        "# Initialize Decision Tree model\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dt_model.fit(X_train_glove, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = dt_model.predict(X_test_glove)\n",
        "\n",
        "# Evaluate the model\n",
        "print('Decision Tree with GloVe')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inxJYSpbhsoS",
        "outputId": "327457cb-47c1-4ece-9e0b-65a5bf64b760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree with GloVe\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.79      0.79      4935\n",
            "           1       0.80      0.79      0.79      5063\n",
            "\n",
            "    accuracy                           0.79      9998\n",
            "   macro avg       0.79      0.79      0.79      9998\n",
            "weighted avg       0.79      0.79      0.79      9998\n",
            "\n",
            "Accuracy: 0.7920584116823365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction using tfidf and Model Training using Decision Tree"
      ],
      "metadata": {
        "id": "1f03vC3YiLY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Feature extraction using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dt_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = dt_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "print('Decision Tree with TF-IDF')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuD5e0GZiNy9",
        "outputId": "8425ae3c-6382-44a1-eb52-6a4ddd4be288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree with TF-IDF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.84      4935\n",
            "           1       0.84      0.83      0.84      5063\n",
            "\n",
            "    accuracy                           0.84      9998\n",
            "   macro avg       0.84      0.84      0.84      9998\n",
            "weighted avg       0.84      0.84      0.84      9998\n",
            "\n",
            "Accuracy: 0.8384676935387078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction using CountVectorizer and Model Training using Decision Tree\n",
        "\n"
      ],
      "metadata": {
        "id": "kBU-9YaeinxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "# Feature extraction using CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=5000)  # Adjust max_features as needed\n",
        "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
        "X_test_counts = count_vectorizer.transform(X_test)\n",
        "\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dt_model.fit(X_train_counts, y_train)\n",
        "\n",
        "y_pred = dt_model.predict(X_test_counts)\n",
        "\n",
        "# Evaluate the model\n",
        "print('Decision Tree with CountVectorizer')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYAnNmEsirKj",
        "outputId": "ee5daf66-de83-4a6b-ec4f-bd7b4d6306b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree with CountVectorizer\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82      4935\n",
            "           1       0.82      0.84      0.83      5063\n",
            "\n",
            "    accuracy                           0.83      9998\n",
            "   macro avg       0.83      0.83      0.83      9998\n",
            "weighted avg       0.83      0.83      0.83      9998\n",
            "\n",
            "Accuracy: 0.8271654330866173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction using Word2Vec and Model Training using Decision Tree\n"
      ],
      "metadata": {
        "id": "IjN60GTgi__i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "X_train_tokens = X_train.apply(word_tokenize)\n",
        "\n",
        "w2v_model = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "def document_vector(tokens, model, vector_size):\n",
        "    token_vectors = [model.wv[token] for token in tokens if token in model.wv.key_to_index]\n",
        "    if not token_vectors:\n",
        "        return np.zeros(vector_size)\n",
        "    return np.mean(token_vectors, axis=0)\n",
        "\n",
        "\n",
        "X_train_w2v = np.array([document_vector(tokens, w2v_model, 100) for tokens in X_train_tokens])\n",
        "\n",
        "# Tokenize and compute document vectors for test set\n",
        "X_test_tokens = X_test.apply(word_tokenize)\n",
        "X_test_w2v = np.array([document_vector(tokens, w2v_model, 100) for tokens in X_test_tokens])\n",
        "# Initialize Decision Tree model\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dt_model.fit(X_train_w2v, y_train)\n",
        "# Make predictions\n",
        "y_pred = dt_model.predict(X_test_w2v)\n",
        "\n",
        "# Evaluate the model\n",
        "print('Decision Tree with Word2Vec')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB4leyEkjClJ",
        "outputId": "1225c6ad-3323-45e4-a293-af8602a62283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree with Word2Vec\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84      4935\n",
            "           1       0.84      0.84      0.84      5063\n",
            "\n",
            "    accuracy                           0.84      9998\n",
            "   macro avg       0.84      0.84      0.84      9998\n",
            "weighted avg       0.84      0.84      0.84      9998\n",
            "\n",
            "Accuracy: 0.8424684936987398\n"
          ]
        }
      ]
    }
  ]
}